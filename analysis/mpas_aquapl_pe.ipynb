{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d67a627d-3d81-4b59-815b-56f8cf3ef058",
   "metadata": {},
   "source": [
    "Note book to assess precipitation efficiency in Rosi's MPAS aquaplanet simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b8e7a1",
   "metadata": {},
   "source": [
    "### Main settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "107297ce-9b59-4ce4-aad0-e3e85bf32564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f407e4f",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a303978e-da2a-4b60-8e44-5515e8463db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of files\n",
    "def get_file_list():\n",
    "    import subprocess\n",
    "    data_path = '/glade/campaign/mmm/dpm/rberrios/glade_scratch/MPAS_APE/aqua_sstmax10N_ASD/CTL/TC_3km/'\n",
    "    process = subprocess.Popen(['ls '+data_path+'waterPaths.2000-05-0*'],shell=True,\n",
    "        stdout=subprocess.PIPE,universal_newlines=True)\n",
    "    file_list = process.stdout.readlines()\n",
    "    for ifile in range(len(file_list)):\n",
    "        file_list[ifile] = file_list[ifile].strip()\n",
    "        # Split to retain only the file name, remove path\n",
    "        file_list[ifile] = file_list[ifile].split('/')[-1]\n",
    "    process = subprocess.Popen(['ls '+data_path+'waterPaths.2000-05-10*'],shell=True,\n",
    "        stdout=subprocess.PIPE,universal_newlines=True)\n",
    "    addfile_list = process.stdout.readlines()\n",
    "    for ifile in range(len(addfile_list)):\n",
    "        addfile_list[ifile] = addfile_list[ifile].strip()\n",
    "        # Split to retain only the file name, remove path\n",
    "        addfile_list[ifile] = addfile_list[ifile].split('/')[-1]\n",
    "    # Combine the results\n",
    "    file_list.extend(addfile_list)\n",
    "    return file_list\n",
    "\n",
    "file_list = get_file_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf5e9677",
   "metadata": {},
   "outputs": [],
   "source": [
    "scdir = '/glade/derecho/scratch/ruppert/tc-crfrad/pickle_out/'\n",
    "\n",
    "test_str = [\"CTL\",\"HOMO_RAD\"]\n",
    "pclass_names = ['DC', 'CG', 'SC', 'ST', 'AN']\n",
    "# pclass_names=[\"Deep\", \"Congestus\", \"Shallow\", \"Stratiform\", \"Anvil\"]#, \"DSA\"] # DSA isn't there yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83c88eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not ready:  /glade/derecho/scratch/ruppert/tc-crfrad/pickle_out/PE_massFlux_HOMO_RAD_2000-05-08_06.pickle\n",
      "File not ready:  /glade/derecho/scratch/ruppert/tc-crfrad/pickle_out/PE_massFlux_HOMO_RAD_2000-05-08_12.pickle\n",
      "File not ready:  /glade/derecho/scratch/ruppert/tc-crfrad/pickle_out/PE_massFlux_HOMO_RAD_2000-05-08_18.pickle\n",
      "File not ready:  /glade/derecho/scratch/ruppert/tc-crfrad/pickle_out/PE_massFlux_HOMO_RAD_2000-05-09_00.pickle\n",
      "File not ready:  /glade/derecho/scratch/ruppert/tc-crfrad/pickle_out/PE_massFlux_HOMO_RAD_2000-05-09_06.pickle\n",
      "File not ready:  /glade/derecho/scratch/ruppert/tc-crfrad/pickle_out/PE_massFlux_HOMO_RAD_2000-05-09_12.pickle\n",
      "File not ready:  /glade/derecho/scratch/ruppert/tc-crfrad/pickle_out/PE_massFlux_HOMO_RAD_2000-05-09_18.pickle\n",
      "File not ready:  /glade/derecho/scratch/ruppert/tc-crfrad/pickle_out/PE_massFlux_HOMO_RAD_2000-05-10_00.pickle\n",
      "File not ready:  /glade/derecho/scratch/ruppert/tc-crfrad/pickle_out/PE_massFlux_HOMO_RAD_2000-05-10_06.pickle\n",
      "File not ready:  /glade/derecho/scratch/ruppert/tc-crfrad/pickle_out/PE_massFlux_HOMO_RAD_2000-05-10_12.pickle\n",
      "File not ready:  /glade/derecho/scratch/ruppert/tc-crfrad/pickle_out/PE_massFlux_HOMO_RAD_2000-05-10_18.pickle\n"
     ]
    }
   ],
   "source": [
    "PE_massFlux = {}\n",
    "\n",
    "for expName in test_str:\n",
    "\n",
    "    PE_massFlux[expName] = {}\n",
    "    for iname in pclass_names:\n",
    "        PE_massFlux[expName][iname] = []\n",
    "\n",
    "    for ifile in file_list:\n",
    "\n",
    "        parts = ifile.split('.')\n",
    "        date = parts[1]\n",
    "        pickle_file = f\"{scdir}PE_massFlux_{expName}_{date}.pickle\"\n",
    "\n",
    "        # Read in variables from pickle\n",
    "        try:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                PE_thisExp = pickle.load(f)\n",
    "\n",
    "            for ikey in PE_thisExp.keys():\n",
    "                PE_massFlux[expName][ikey].append(PE_thisExp[ikey])\n",
    "        except:\n",
    "            print('File not ready: ',pickle_file)\n",
    "            pass\n",
    "\n",
    "    for ikey in PE_thisExp.keys():\n",
    "        PE_massFlux[expName][ikey] = np.array(PE_massFlux[expName][ikey])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03296b3f",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8da5b0",
   "metadata": {},
   "source": [
    "#### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7948555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute running mean\n",
    "def running_mean_conf(time_series):\n",
    "    nd_smooth    = 6 # days\n",
    "    nd_window_ci = 6\n",
    "    # nd_smooth    = 20 # days\n",
    "    # nd_window_ci = 20\n",
    "    ntpday = 4 # timesteps per day\n",
    "    window_size = nd_smooth*ntpday  # Adjust as needed\n",
    "    window_size_ci = nd_window_ci*ntpday  # Adjust as needed\n",
    "    tser_smooth = np.convolve(time_series, np.ones(window_size) / window_size, mode='valid')\n",
    "    tser_ci = np.convolve(time_series, np.ones(window_size_ci) / window_size_ci, mode='valid')\n",
    "    # Compute standard error of the mean\n",
    "    standard_error = stats.sem(time_series)  # Standard error of the original data\n",
    "    z_score = 1.96 # Z-score for 95% confidence interval\n",
    "    confidence_interval = z_score * standard_error  # 95% confidence interval\n",
    "    # confidence_interval = np.zeros_like(tser_ci)\n",
    "    # # for i in range(len(tser_smooth)):\n",
    "    # for i in range(len(tser_ci)):\n",
    "    #     subset = time_series[i:i+window_size_ci]\n",
    "    #     standard_error = stats.sem(subset)\n",
    "    #     confidence_interval[i] = z_score * standard_error\n",
    "    #     # Q1 = np.percentile(subset, 25)\n",
    "    #     # Q3 = np.percentile(subset, 75)\n",
    "    #     # IQR = Q3 - Q1\n",
    "    #     # confidence_interval[i] = IQR/2\n",
    "    return tser_smooth, confidence_interval, window_size, tser_ci, window_size_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20caeff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(title, all_vars_imean, subtitles=None, units=None, ctlanom=False,\n",
    "                     conf_shading=True, do_legend=True):\n",
    "    nprof = all_vars_imean.shape[0]\n",
    "    i_nt = all_vars_imean.shape[-1]\n",
    "    # create figure\n",
    "    fig_x = 7\n",
    "    fig_y = 2.0*nprof + 1\n",
    "    fig, axs = plt.subplots(nprof,1, figsize=(fig_x,fig_y), layout=\"constrained\", dpi=300) # row, column\n",
    "    # fig.suptitle(title)\n",
    "    for iprof, ax in enumerate(axs):\n",
    "        pltvar = np.copy(all_vars_imean[iprof])\n",
    "        if ctlanom:\n",
    "            pltvar -= pltvar[:,0,:][:,np.newaxis,:]\n",
    "        # Plot all sensitivity tests for variable\n",
    "        for itest in range(ntest):\n",
    "            tser = pltvar[:,itest,:]\n",
    "            # Smooth time series\n",
    "            tser = running_mean_conf(tser)\n",
    "            mean, low, high = mean_confidence_interval(tser)\n",
    "            ax.plot(mean, linestyle=linestyle[itest], color=linecolor[itest], label=tests_str[itest])\n",
    "            if conf_shading:\n",
    "                # if (itest == 0) or (itest == 1):\n",
    "                xdim = range(0,i_nt)\n",
    "                ax.fill_between(xdim, high, low, alpha=0.2, color=linecolor[itest])\n",
    "        ax.set_title(subtitles[iprof])\n",
    "        ax.set_ylabel(units[iprof])\n",
    "        if iprof < nprof-1:\n",
    "            sns.despine(offset=10,ax=ax, bottom=True)\n",
    "            # Remove tick labels\n",
    "            ax.set_xticks([])\n",
    "        else:\n",
    "            sns.despine(offset=10,ax=ax)\n",
    "            ax.set_xlabel('Time [hours]')\n",
    "        if do_legend and iprof == 0:\n",
    "            ax.legend(loc=\"lower left\", frameon=False, fontsize=12)#, bbox_to_anchor=(0.05, 0.05))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608433d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
