{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d67a627d-3d81-4b59-815b-56f8cf3ef058",
   "metadata": {},
   "source": [
    "#### Calculate and write out vmf, p-class, and PE from Rosi's MPAS simulations\n",
    "\n",
    "Using modified code from Rosi's notebooks\n",
    "\n",
    "Optimized by gemini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c1d3be",
   "metadata": {},
   "source": [
    "### Main settings and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107297ce-9b59-4ce4-aad0-e3e85bf32564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78e54c",
   "metadata": {},
   "source": [
    "#### Start cluster and scale it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f03a4cf-0100-438f-9560-5d4e7d1cb7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#PBS -N dask-wk23-hpc\n",
      "#PBS -q casper\n",
      "#PBS -A UOKL0049\n",
      "#PBS -l select=1:ncpus=1:mem=10GB\n",
      "#PBS -l walltime=12:00:00\n",
      "#PBS -e /glade/derecho/scratch/ruppert/dask//\n",
      "#PBS -o /glade/derecho/scratch/ruppert/dask//\n",
      "\n",
      "/glade/work/ruppert/conda-envs/plotting/bin/python -m distributed.cli.dask_worker tcp://128.117.211.222:46297 --name dummy-name --nthreads 1 --memory-limit 10.00GiB --nanny --death-timeout 60 --local-directory /glade/derecho/scratch/ruppert/dask/ --interface ext\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from ncar_jobqueue import NCARCluster\n",
    "# cluster = PBSCluster()\n",
    "# cluster.scale(4 * 9) # Ask for 4 x 9 workers\n",
    "# cluster\n",
    "\n",
    "from dask_jobqueue import PBSCluster\n",
    "# Create a PBS cluster object\n",
    "# cluster = PBSCluster(\n",
    "#     job_name = 'dask-wk23-hpc',\n",
    "#     cores = 1,\n",
    "#     processes = 1,\n",
    "#     log_directory = '/glade/derecho/scratch/rberrios/dask/',\n",
    "#     local_directory = '/glade/derecho/scratch/rberrios/dask/',\n",
    "#     resource_spec = 'select=1:ncpus=1:mem=10GB',\n",
    "#     queue = 'casper',\n",
    "#     walltime = '12:00:00',\n",
    "#     interface = 'mgt'\n",
    "# )\n",
    "cluster = PBSCluster(\n",
    "    job_name = 'dask-wk23-hpc',\n",
    "    cores = 1,\n",
    "    processes = 1,\n",
    "    memory = '10GiB',\n",
    "    account = 'UOKL0049',\n",
    "    log_directory = '/glade/derecho/scratch/ruppert/dask/',\n",
    "    local_directory = '/glade/derecho/scratch/ruppert/dask/',\n",
    "    resource_spec = 'select=1:ncpus=1:mem=10GB',\n",
    "    queue = 'casper',\n",
    "    # queue = 'main',\n",
    "    walltime = '12:00:00',\n",
    "    interface = 'ext'\n",
    ")\n",
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57234228-6b1a-4ad7-a53e-edefc0ccf414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-ddd7f124-815f-11f0-9a73-ac1f6bc7cc7e</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.PBSCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://128.117.211.222:8787/status\" target=\"_blank\">http://128.117.211.222:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">PBSCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">c0150bc6</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://128.117.211.222:8787/status\" target=\"_blank\">http://128.117.211.222:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-3e081807-37ea-421a-85c3-90f094da2faf</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://128.117.211.222:46297\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://128.117.211.222:8787/status\" target=\"_blank\">http://128.117.211.222:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://128.117.211.222:46297' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster) # Connect this local process to remote workers\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8824d7af-bb12-4ba7-b271-f2d1e95aa192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the cluster to n workers (which will use n jobs here)\n",
    "ncpu = 36\n",
    "# ncpu = 24\n",
    "# ncpu = 10\n",
    "# ncpu = 18\n",
    "cluster.scale(ncpu)\n",
    "\n",
    "# Block progress until workers have spawned (typically only in demos and benchmarks!)\n",
    "client.wait_for_workers(ncpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30b5af2",
   "metadata": {},
   "source": [
    "#### Set paths, read initial conditions, find tropical indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a303978e-da2a-4b60-8e44-5515e8463db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = \"TC_3km\"\n",
    "grid_path = \"/glade/work/rberrios/MPAS/aqua_sstmax10N_ASD/plus4K/TC_3km/x5.tropical_3km_10N.init.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4ab09b-2203-4476-85d5-86e1fbeafb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = xr.open_dataset(grid_path)\n",
    "latCell = np.degrees(grid.latCell)\n",
    "lonCell = np.degrees(grid.lonCell)\n",
    "areaCell = grid.areaCell\n",
    "\n",
    "#find indexes within desired latitudinal range\n",
    "latbounds = [15, 20.0]\n",
    "# latbounds = [0, 15.0]\n",
    "ind_within_lat = np.where( (latCell >= latbounds[0]) & (latCell <= latbounds[1]) )[0]\n",
    "\n",
    "areaCell_tropical = areaCell.isel(nCells=ind_within_lat)\n",
    "# len(ind_within_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41311849",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378e1343",
   "metadata": {},
   "source": [
    "#### P-class function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcfbbf73-1ddb-4e16-9148-282f344b6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Column-based precipitation classification algorithm designed for application on\n",
    "# numerical model output.\n",
    "# \n",
    "# It has been designed using WRF model output using the Thompson and Eidhammer\n",
    "# (2014, JAS) microphysics scheme, which has 2 liquid and 3 frozen categories as\n",
    "# listed and expected below.\n",
    "# \n",
    "# Input:\n",
    "# \n",
    "#       Q_INT: n-D array of vertically integrated hydrometeors as f(q, X), where\n",
    "#               q(5) is the hydrometeor dimension, arranged as\n",
    "#               ['QCLOUD', 'QRAIN', 'QICE', 'QSNOW', 'QGRAUP'] and X includes the\n",
    "#               remaining (time and) spatial dimensions.\n",
    "# Returns:\n",
    "# \n",
    "#       C_TYPE: (n-2)-D array as f(X) with classification results:\n",
    "#               0: non-cloud\n",
    "#           Convective:\n",
    "#               1: deep convective\n",
    "#               2: congestus\n",
    "#               3: shallow\n",
    "#           Layered:\n",
    "#               4: stratiform\n",
    "#               5: anvil (weaker rainfall)\n",
    "# \n",
    "# Emily Luschen - emily.w.luschen-1@ou.edu\n",
    "# James Ruppert - jruppert@ou.edu\n",
    "# 5/19/23\n",
    "# Rosi RB - modified to ingest water paths and to return dask arrays\n",
    "\n",
    "def precip_class(q_int):\n",
    "    shape = q_int.shape\n",
    "    ndims=len(shape)\n",
    "    shape_out = shape[1:ndims]\n",
    "\n",
    "    # Integrated water variables\n",
    "    # Ensure these are Dask arrays if q_int is a Dask array\n",
    "    LWP = q_int[0]\n",
    "    IWP = q_int[1]\n",
    "    # For Q_INT input, q_int[2] is QICE, q_int[3] is QSNOW, q_int[4] is QGRAUP\n",
    "    # Your original code used q_int[2] for rain, q_int[3] for graupel.\n",
    "    # Make sure this indexing is consistent with your actual 'q_int' structure.\n",
    "    # Based on the function docstring: ['QCLOUD', 'QRAIN', 'QICE', 'QSNOW', 'QGRAUP']\n",
    "    # And your q_int = np.array([ds.lwp, ds.iwp, ds.rwp, ds.gwp]), this means:\n",
    "    # q_int[0] = lwp (QCLOUD + QRAIN combined in your data?)\n",
    "    # q_int[1] = iwp (QICE + QSNOW + QGRAUP combined in your data?)\n",
    "    # q_int[2] = rwp (QRAIN from your data)\n",
    "    # q_int[3] = gwp (QGRAUP from your data)\n",
    "    # So, the original function's `q_int[2]` (for rain_thresh) is `rwp` (your q_int[2])\n",
    "    # and `q_int[3]` (for graup_thresh) is `gwp` (your q_int[3]).\n",
    "    # This seems consistent, just making sure the comments are aligned.\n",
    "\n",
    "    RWP = q_int[2] # Rain Water Path\n",
    "    GWP = q_int[3] # Graupel Water Path\n",
    "\n",
    "    TWP = LWP + IWP\n",
    "\n",
    "    # Use xarray.where for masking with Dask arrays\n",
    "    # Ensure LWP is not zero before division to avoid inf/nan\n",
    "    cr = xr.where(LWP != 0, IWP / LWP, np.inf) # Use np.inf for where LWP is zero, so cr_thresh condition handles it\n",
    "\n",
    "    # Threshold parameters (unchanged)\n",
    "    twp_thresh = 1e-1\n",
    "    cr_thresh = 2\n",
    "    graup_thresh = 1e-4\n",
    "    rain_thresh_conv = 1e-1\n",
    "    rain_thresh_strat = 1e-2\n",
    "\n",
    "    # Initialize output array as a Dask array of zeros\n",
    "    # Use dask.array.zeros or xarray.zeros_like to create a Dask-backed array\n",
    "    # The shape should be (Time, nCells) after the initial q_int[0] selection\n",
    "    # Assuming q_int has dimensions (variable, Time, nCells)\n",
    "    c_type_shape = LWP.shape # Should be (Time, nCells)\n",
    "    c_type = da.zeros(c_type_shape, dtype=np.int8)\n",
    "\n",
    "    # Use dask.array.where for efficient boolean indexing with Dask arrays\n",
    "    # Deep convection\n",
    "    condition_dc = ((LWP != 0) & (TWP > twp_thresh) & \\\n",
    "                    (cr <= cr_thresh) & \\\n",
    "                    (RWP >= rain_thresh_conv) & \\\n",
    "                    (GWP >= graup_thresh))\n",
    "    c_type = da.where(condition_dc, 1, c_type)\n",
    "\n",
    "    # Congestus\n",
    "    condition_cg = ((LWP != 0) & (TWP > twp_thresh) & \\\n",
    "                    (cr <= cr_thresh) & \\\n",
    "                    (RWP >= rain_thresh_conv) & \\\n",
    "                    (GWP < graup_thresh))\n",
    "    c_type = da.where(condition_cg, 2, c_type)\n",
    "\n",
    "    # Shallow\n",
    "    condition_sc = ((LWP != 0) & (TWP > twp_thresh) & \\\n",
    "                    (cr <= cr_thresh) & \\\n",
    "                    (RWP < rain_thresh_conv))\n",
    "    c_type = da.where(condition_sc, 3, c_type)\n",
    "\n",
    "    # Stratiform\n",
    "    condition_st = ((LWP != 0) & (TWP > twp_thresh) & \\\n",
    "                    (cr > cr_thresh) & \\\n",
    "                    (RWP >= rain_thresh_strat))\n",
    "    c_type = da.where(condition_st, 4, c_type)\n",
    "\n",
    "    # Anvil\n",
    "    condition_an = ((LWP != 0) & (TWP > twp_thresh) & \\\n",
    "                    (cr > cr_thresh) & \\\n",
    "                    (RWP < rain_thresh_strat))\n",
    "    c_type = da.where(condition_an, 5, c_type)\n",
    "\n",
    "    return c_type # This will return a Dask array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3fe7f",
   "metadata": {},
   "source": [
    "#### Function to get PE, VMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673e43e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to calculate mass-flux based precipitation efficiency ###\n",
    "def calc_massFlux_precipitationEfficiency(M_u, M_d, areaCell, c_type_dask):\n",
    "\n",
    "    # ntime = M_u.shape[0]\n",
    "\n",
    "    # mu_clouds = da.zeros((ntime, 6), dtype=M_u.dtype) # Assuming M_u is a Dask array\n",
    "    # md_clouds = da.zeros((ntime, 6), dtype=M_u.dtype)\n",
    "    # count_clouds = da.zeros((ntime, 6), dtype=M_u.dtype) # How many cells contribute to each cloud type\n",
    "    mu_clouds = da.zeros(6, dtype=M_u.dtype) # Assuming M_u is a Dask array\n",
    "    md_clouds = da.zeros(6, dtype=M_u.dtype)\n",
    "    count_clouds = da.zeros(6, dtype=M_u.dtype) # How many cells contribute to each cloud type\n",
    "\n",
    "    # for it in range(ntime):\n",
    "\n",
    "    for i in np.arange(1, 7): # Assuming c_type_dask ranges from 1 to 5\n",
    "    # for i in np.arange(6, 7): # Assuming c_type_dask ranges from 1 to 5\n",
    "\n",
    "        # Ensure mask is computed as a dask array if c_type_dask is dask\n",
    "        if i == 6:\n",
    "            mask = ((c_type_dask == 1) | (c_type_dask == 4) | (c_type_dask == 5)) # Combine DC, ST, AN\n",
    "        else:\n",
    "            mask = (c_type_dask == i)\n",
    "\n",
    "        count = mask.sum()\n",
    "\n",
    "        # epsilon_mask = epsilon_v2.where(mask)\n",
    "        Md_mask = M_d.where(mask)\n",
    "        Mu_mask = M_u.where(mask)\n",
    "        # areaCell_mask = da.repeat(areaCell[da.newaxis,...], M_d.shape[0]).where(mask) # areaCell should ideally be broadcastable or have matching dims\n",
    "        areaCell_mask = areaCell.where(mask) # areaCell should ideally be broadcastable or have matching dims\n",
    "\n",
    "        # It's better to compute the weighted sum and total area, then divide.\n",
    "        # This will create a dask graph. The .compute() will happen outside the loop\n",
    "        # if the list is returned, or if you explicitly call .compute() here.\n",
    "        # For a list, you'd typically gather them later.\n",
    "        # weighted_sum = (epsilon_mask * areaCell_mask).sum(dim='nCells', skipna=True)\n",
    "        total_area = areaCell_mask.sum(dim='nCells', skipna=True)\n",
    "        Mu_weighted_sum = (Mu_mask * areaCell_mask).sum(dim='nCells', skipna=True)\n",
    "        Md_weighted_sum = (Md_mask * areaCell_mask).sum(dim='nCells', skipna=True)\n",
    "\n",
    "        # Handle division by zero for total_area to avoid NaN/inf\n",
    "        # epsilon_mask_mean_v2 = (weighted_sum / total_area).where(total_area != 0)\n",
    "        Mu_mask_mean = (Mu_weighted_sum / total_area).where(total_area != 0)\n",
    "        Md_mask_mean = (Md_weighted_sum / total_area).where(total_area != 0)\n",
    "\n",
    "        # Finally, calculate epsilon for cloud type with averaged Md, Mu\n",
    "        # V1\n",
    "        # epsilon_mask_mean_v1 = 1.0 - (Md_mask_mean / Mu_mask_mean).where(Mu_mask_mean != 0) # Avoid inf/NaN where M_d is zero\n",
    "        # epsilon_clouds.append(epsilon_mask_mean_v1) # Append dask.array.Array objects\n",
    "        # count_clouds.append(count)\n",
    "        # mu_clouds.append(Mu_mask_mean)\n",
    "        # md_clouds.append(Md_mask_mean)\n",
    "        count_clouds[i-1] = count\n",
    "        mu_clouds[i-1] = Mu_mask_mean\n",
    "        md_clouds[i-1] = Md_mask_mean\n",
    "\n",
    "        # Put V2 after V1\n",
    "        # epsilon_clouds.append(epsilon_mask_mean_v2) # Append dask.array.Array objects\n",
    "\n",
    "    # finally, domain-mean\n",
    "    # If you want to compute the domain mean of epsilon for the whole domain (not by cloud type)\n",
    "    # domain_mean_epsilon = (epsilon * areaCell).sum(dim='nCells', skipna=True) / areaCell.sum(dim='nCells', skipna=True)\n",
    "    # You could return both epsilon_clouds and domain_mean_epsilon, or whatever makes sense for your output.\n",
    "    return [count_clouds, mu_clouds, md_clouds] # This will be a list of Dask DataArray "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230b7fc",
   "metadata": {},
   "source": [
    "### Main driver loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62e5396",
   "metadata": {},
   "source": [
    "#### Get file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4fe82a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000-05-04_00.00.00'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of desired file times\n",
    "file_times_arr = np.arange('2000-05-01T06:00:00', '2000-05-11T06:00:00', 6, dtype='datetime64[h]')\n",
    "file_times = [file_times_arr[i].astype('datetime64[D]').astype(str)+'_'+str(file_times_arr[i]).split('T')[1].split(':')[0]+'.00.00' for i in range(len(file_times_arr))]\n",
    "\n",
    "istart_set=11\n",
    "file_times[istart_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090be225",
   "metadata": {},
   "source": [
    "#### Start loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f2eb282-8a39-45a5-8a98-95bad81ccbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loop...\n",
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-04_00.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-04_06.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-04_12.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-04_18.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-05_00.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.43 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-05_06.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-05_12.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-05_18.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-06_00.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-06_06.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.43 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-06_12.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-06_18.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.43 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-07_00.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-07_06.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-07_12.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-07_18.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-08_00.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-08_06.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-08_12.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-08_18.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-09_00.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.43 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-09_06.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-09_12.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-09_18.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-10_00.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-10_06.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-10_12.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-10_18.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: VMF_pclass_CLIM_RAD_2000-05-11_00.00.00_15-20.0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ruppert/conda-envs/plotting/lib/python3.11/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing CLIM_RAD\n",
      "Classification complete.\n",
      "CPU times: user 1h 54min 58s, sys: 18min 51s, total: 2h 13min 49s\n",
      "Wall time: 2h 9min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Main loop\n",
    "import pickle\n",
    "\n",
    "pclass_names = ['DC', 'CG', 'SC', 'ST', 'AN', 'DSA']\n",
    "\n",
    "print('Starting loop...')\n",
    "nCells_chunk_size = 100000\n",
    "\n",
    "exp_names = [\"CTL\", \"HOMO_RAD\", \"CLIM_RAD\"]\n",
    "\n",
    "main_path = \"/glade/campaign/mmm/dpm/rberrios/glade_scratch/MPAS_APE/aqua_sstmax10N_ASD/\"\n",
    "\n",
    "pickle_dir = '/glade/derecho/scratch/ruppert/tc-crfrad/pickle_out/'\n",
    "\n",
    "# for expName in exp_names:\n",
    "for expName in exp_names[2:]:\n",
    "\n",
    "    data_path = f\"{main_path}{expName}/TC_3km/\"\n",
    "    scdir = '/glade/derecho/scratch/ruppert/tc-crfrad/mpas/'+expName+'/'\n",
    "\n",
    "    # data_path = f\"/glade/campaign/mmm/dpm/rberrios/glade_scratch/MPAS_APE/aqua_sstmax10N_ASD/{expName}/TC_3km/\"\n",
    "\n",
    "    # Open the dataset with dask backend. This loads lazily.\n",
    "    # Specify chunks to optimize memory usage and parallel processing.\n",
    "    # You'll need to know typical chunk sizes for your variables, or let xarray guess.\n",
    "    # For large datasets, manual chunking can be critical.\n",
    "    # Example: If 'Time' dimension is large, chunk it. 'nCells' might be good to chunk too.\n",
    "    # ds = xr.open_mfdataset(data_path + \"waterPaths*\", combine=\"nested\", concat_dim=\"Time\",\n",
    "    #                        chunks={'Time': 'auto', 'nCells': 'auto'}) # 'auto' lets Dask guess\n",
    "    # Or specify explicitly, e.g., {'Time': 24, 'nCells': 1000}\n",
    "\n",
    "    if expName == \"CTL\":\n",
    "        istart = 0\n",
    "    elif expName == \"HOMO_RAD\":\n",
    "        istart = 0\n",
    "    elif expName == \"CLIM_RAD\":\n",
    "        istart = istart_set\n",
    "\n",
    "    # for time in file_times:\n",
    "    # for time in file_times[istart:]:\n",
    "    for time in file_times[istart:]:\n",
    "\n",
    "        # print(f\"Processing {expName} for time {time}\")\n",
    "        print(f\"Processing file: VMF_pclass_{expName}_{time}_{str(latbounds[0])}-{str(latbounds[1])}.pickle\")\n",
    "\n",
    "        # print('opening files')\n",
    "        # wp_files = [data_path+'waterPaths.'+time+'.nc' for time in file_times]\n",
    "        wp_files = data_path+'waterPaths.'+time+'.nc'\n",
    "        # ds = xr.open_mfdataset(wp_files,\n",
    "        ds = xr.open_mfdataset(wp_files,\n",
    "                    # combine=\"nested\", concat_dim=\"Time\", \n",
    "                    parallel=True, \n",
    "                    chunks={\"Time\": -1, \"nCells\": nCells_chunk_size})\n",
    "\n",
    "        # vmf_files = [scdir+'vmfs.'+time+'.nc' for time in file_times]\n",
    "        vmf_files = scdir+'vmfs.'+time+'.nc'\n",
    "        # ds_vmf = xr.open_mfdataset(vmf_files,\n",
    "        ds_vmf = xr.open_mfdataset(vmf_files,\n",
    "                    # combine=\"nested\", concat_dim=\"Time\", \n",
    "                    parallel=True,\n",
    "                    chunks={\"Time\": -1, \"nCells\": nCells_chunk_size})\n",
    "\n",
    "        # print()\n",
    "        # print('subsetting')\n",
    "        # Select cells within latitude range. This operation is also lazy if `ds` is Dask-backed.\n",
    "        ds_tropical = ds.isel(nCells=ind_within_lat)\n",
    "        ds_vmf_tropical = ds_vmf.isel(nCells=ind_within_lat)\n",
    "\n",
    "        # print('reading variables')\n",
    "        # Convert to a list of DataArrays, and wrap in dask.array.stack to create a single Dask array\n",
    "        # This creates a Dask-backed array 'q_int_dask' without loading data into memory yet.\n",
    "        q_int_dask = da.stack([\n",
    "            ds_tropical.lwp.data,\n",
    "            ds_tropical.iwp.data,\n",
    "            ds_tropical.rwp.data,\n",
    "            ds_tropical.gwp.data\n",
    "        ], axis=0) # Stack along a new 0th dimension for the different water paths\n",
    "\n",
    "        mu = ds_vmf_tropical.mu\n",
    "        md = ds_vmf_tropical.md\n",
    "\n",
    "        # print('classifying')\n",
    "        # Call the classification function. This will return a Dask array (c_type_dask).\n",
    "        # The actual computation of c_type is still lazy at this point.\n",
    "        c_type_dask = precip_class(q_int_dask)\n",
    "\n",
    "        # print('getting PE')\n",
    "        # Get Mu, Md as a function of PClass\n",
    "        vmf_pclass = calc_massFlux_precipitationEfficiency(mu, md, areaCell_tropical, c_type_dask[0])\n",
    "\n",
    "        # print('daks.compute for VMFs')\n",
    "        results = dask.compute(vmf_pclass)[0] # dask.compute returns a tuple of results\n",
    "        count_results = results[0]\n",
    "        mu_results = results[1]\n",
    "        md_results = results[2]\n",
    "\n",
    "        # Write out to pickle\n",
    "\n",
    "        # pickle_file_out = f\"{scdir}PE_massFlux_{expName}_{time}.pickle\"\n",
    "        pickle_file_out = f\"{pickle_dir}VMF_pclass_{expName}_{time}_{str(latbounds[0])}-{str(latbounds[1])}.pickle\"\n",
    "        # pickle_file_out = f\"{pickle_dir}VMF_{expName}.pickle\"\n",
    "        with open(pickle_file_out, 'wb') as f:\n",
    "            # pickle.dump(PE_thisExp, f)\n",
    "            pickle.dump([count_results, mu_results, md_results], f)\n",
    "\n",
    "    print(f\"Finished processing {expName}\")\n",
    "\n",
    "print('Classification complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f1b07c",
   "metadata": {},
   "source": [
    "### Close cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff3722-87e9-4d64-a6ab-5ff9aa1ec943",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
